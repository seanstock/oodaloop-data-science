{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve Databricks credentials\n",
    "databricks_host = os.getenv('DATABRICKS_HOST')\n",
    "databricks_token = os.getenv('DATABRICKS_TOKEN')\n",
    "warehouse_id = os.getenv('WAREHOUSE_ID')\n",
    "catalog = os.getenv('CATALOG')\n",
    "schema = os.getenv('SCHEMA')\n",
    "\n",
    "print(f\"Databricks Host: {databricks_host}\")\n",
    "print(f\"Databricks Token is set: {'Yes' if databricks_token else 'No'}\")\n",
    "print(f\"Warehouse ID: {warehouse_id}\")\n",
    "print(f\"Catalog: {catalog}\")\n",
    "print(f\"Schema: {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = DatabricksSession.builder.sdkConfig(\n",
    "    host = databricks_host,\n",
    "    token = databricks_token,\n",
    "    cluster_id = warehouse_id, # cluster_id is the warehouse_id\n",
    "    catalog = catalog,\n",
    "    schema = schema\n",
    ").getOrCreate()\n",
    "\n",
    "def execute_sql(query: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executes a SQL query on Databricks and returns the result as a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        query: The SQL query string to execute.\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame containing the query results.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Executing query: {query[:100]}...\")\n",
    "        df = spark.sql(query).toPandas()\n",
    "        print(\"Query successful, returning DataFrame.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return pd.DataFrame() # Return empty DataFrame on error\n",
    "\n",
    "# Example usage:\n",
    "# my_data_df = execute_sql('SELECT * FROM my_table LIMIT 10')\n",
    "# display(my_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load data from the `metadata` or `sql` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: df = pd.read_csv('path/to/your/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
} 